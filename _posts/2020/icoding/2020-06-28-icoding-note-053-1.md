---
layout: post
title: 飞天班第53节：数据切分设计方案Sharding-jdbc
category: icoding-edu
tags: [icoding-edu]
keywords: mysql
excerpt: 客户端代理模式数据源连接管理应用Sharingjdbc,引入使用，配置广播表，绑定表，读写分离
lock: noneed
---

## 1. Sharding-Jdbc介绍

官方文档：[https://shardingsphere.apache.org/](https://shardingsphere.apache.org/)

![](/assets/images/2020/icoding/mysql/sharding-sphere.jpg)

sharingSphere 包括，使用时一定要多看看用户手册

![](/assets/images/2020/icoding/mysql/sharding-sphere2.jpg)

Sharding-JDBC是ShardingSphere的第一个产品，也是ShardingSphere的前身。

- sharding-jdbc是一个分布式的关系型数据库中间件
- <font color=red>客户端代理模式，不需要搭建服务器，只需要后端数据库即可，有个IDE就行了</font>
- 定位于轻量级的Java框架，以jar的方式提供服务
- 可以理解为增强版的jdbc驱动
- 完全兼容主流的ORM框架，如Mybatis-plus
- 架构：

![](/assets/images/2020/icoding/mysql/sharding-jdbc.jpg)

- sharding-jdbc提供了4种配置
  - Java API
  - yaml (层级深)
  - properties
  - spring命名空间

- **与MyCat的区别**
  - <font color=red>MyCat是服务端的代理模式，Sharding-Jdbc是客户端代理模式</font>
  - 实际开发中如果企业有DBA建议使用MyCat，都是开发人员建议使用sharding-jdbc
  - MyCat不支持在一个库内进行水平分表，而sharding-jdbc支持在同一个数据库中进行水平分表
- 名词解释
  - 逻辑表：物理表的合并表
  - 真实表：存放数据的地方
  - 数据节点：存储数据的MySQL节点
  - 绑定表：相当于MyCat中的子表
  - 广播表：相当于MyCat中的全局表

## 2. Sharding-Jdbc引入使用

```shell
# 0.首先在两个MySQL实例上分别创建数据库：shard_order
# 1.在两个数据库创建两个表order_info_1,order_info_2
CREATE TABLE `order_info_1` (
  `id` int(11) NOT NULL,
  `order_amount` decimal(10,2) DEFAULT NULL,
  `order_status` int(255) DEFAULT NULL,
  `user_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
CREATE TABLE `order_info_2` (
  `id` int(11) NOT NULL,
  `order_amount` decimal(10,2) DEFAULT NULL,
  `order_status` int(255) DEFAULT NULL,
  `user_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
# 2.切分规则，按照id的奇偶数切分到两个数据库，在自己的数据库按照user_id进行表切分
```

![](/assets/images/2020/icoding/mysql/shard-order.jpg)

新建一个SpringBoot项目

代码导入POM依赖

```xml
<dependency>
  <groupId>org.apache.shardingsphere</groupId>
  <artifactId>sharding-jdbc-spring-boot-starter</artifactId>
  <version>4.0.0-RC2</version>
</dependency>
```

applicaiton.properties配置

```shell
# 给两个数据源命名
spring.shardingsphere.datasource.names=ds0,ds1
# 数据源链接ds0要和命名一致
spring.shardingsphere.datasource.ds0.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds0.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.ds0.jdbcUrl=jdbc:mysql://39.103.163.215:3306/shard_order
spring.shardingsphere.datasource.ds0.username=gavin
spring.shardingsphere.datasource.ds0.password=123456
# 数据源链接ds1要和命名一致
spring.shardingsphere.datasource.ds1.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds1.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.ds1.jdbcUrl=jdbc:mysql://39.101.221.95:3306/shard_order
spring.shardingsphere.datasource.ds1.username=gavin
spring.shardingsphere.datasource.ds1.password=123456
# 具体的分片规则,基于数据节点
spring.shardingsphere.sharding.tables.order_info.actual-data-nodes=ds$->{0..1}.order_info_$->{1..2}
# 分库的规则
spring.shardingsphere.sharding.tables.order_info.database-strategy.inline.sharding-column=id
spring.shardingsphere.sharding.tables.order_info.database-strategy.inline.algorithm-expression=ds$->{id % 2}
# 分表的规则
spring.shardingsphere.sharding.tables.order_info.table-strategy.inline.sharding-column=user_id
spring.shardingsphere.sharding.tables.order_info.table-strategy.inline.algorithm-expression=order_info_$->{user_id % 2 + 1}
```

```java
// 使用jdbcTemplate 测试代码
@SpringBootTest
class ShardingjdbcProjectApplicationTests {
    @Autowired
    JdbcTemplate jdbcTemplate;

    @Test
    void insertTest(){
        String sql = "insert into order_info(id,order_amount,order_status,user_id) values(3,213.88,1,2)";
        int i = jdbcTemplate.update(sql);
        System.out.println("影响行数:"+i);
    }
}
```

结合 mybatis-plus  ORM 框架 测试代码

> 插入数据

```java
@Autowired
OrderInfoService orderInfoService;

@Test
void contextLoads() {
		OrderInfo orderInfo = new OrderInfo();
		orderInfo.setId(2).setOrderAmount(BigDecimal.valueOf(300)).setOrderStatus(1).setUserId(1);
		orderInfoService.save(orderInfo);

		OrderInfo orderInfo2 = new OrderInfo();
		orderInfo2.setId(3).setOrderAmount(BigDecimal.valueOf(213)).setOrderStatus(1).setUserId(2);
		orderInfoService.save(orderInfo2);
}
```

报错，一个坑,

![](/assets/images/2020/icoding/mysql/shardingDataSource-jdbc.jpg)

```properties
spring.shardingsphere.datasource.ds0.url=jdbc:mysql://39.103.163.215:3306/shard_order
# 修改为：
spring.shardingsphere.datasource.ds0.jdbcUrl=jdbc:mysql://39.103.163.215:3306/shard_order
```

运行成功后，发现两张订单表已分库分表

![](/assets/images/2020/icoding/mysql/sharding-jdbc-213.jpg)

![](/assets/images/2020/icoding/mysql/sharding-jdbc-214.jpg)

> 查询所有数据

```java
// 使用上没有任何变化
@Test
void listAll() {
  List<OrderInfo> list = orderInfoService.list();
  list.forEach(System.out::println);
}
```

![](/assets/images/2020/icoding/mysql/sharding-jdbc-list-all.jpg)



## 3. 配置广播表

相当于mycat的全局表(每个库的数据一样，就是全部数据)，先在两个库上创建广播表province_info

应用场景：数据量不大，并且不希望数据分片的表，如配置表，省市区表

```sql
CREATE TABLE `province_info` (
  `id` int(11) NOT NULL,
  `name` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
```

在application.properties里增加配置

```shell
spring.shardingsphere.sharding.broadcast-tables=province_info
```

测试插入和查询的代码

```java
@Test
void insertBroadcast(){
  String sql = "insert into province_info(id,name) values(1,'beijing')";
  int i = jdbcTemplate.update(sql);
  System.out.println("******* 影响的结果："+i);
}

@Test
void selectBroadcast(){
  String sql = "select * from province_info";
  List<Map<String,Object>> result = jdbcTemplate.queryForList(sql);
  for (Map<String,Object> val: result) {
    System.out.println("=========== "+val.get("id")+" ----- "+val.get("name"));
  }
}
```



## 4. 配置绑定表

相当于mycat的主表子表管理，首先按照order_info的建表顺序创建order_item分别在两个库上建立order_item_1,order_item_2

```shell
CREATE TABLE `order_item_1` (
  `id` int(11) DEFAULT NULL,
  `product_name` varchar(255) DEFAULT NULL,
  `order_id` int(11) DEFAULT NULL,
  `user_id` int(11) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

CREATE TABLE `order_item_2` (
  `id` int(11) DEFAULT NULL,
  `product_name` varchar(255) DEFAULT NULL,
  `order_id` int(11) DEFAULT NULL,
  `user_id` int(11) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
```

![](/assets/images/2020/icoding/mysql/order-item.jpg)

配置绑定表，将两个item表的分片逻辑和order_info保持一致

```shell
# 给两个数据源命名
spring.shardingsphere.datasource.names=ds0,ds1
# 数据源链接ds0要和命名一致
spring.shardingsphere.datasource.ds0.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds0.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.ds0.jdbcUrl=jdbc:mysql://39.103.163.215:3306/shard_order
spring.shardingsphere.datasource.ds0.username=gavin
spring.shardingsphere.datasource.ds0.password=123456
# 数据源链接ds1要和命名一致
spring.shardingsphere.datasource.ds1.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds1.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.ds1.jdbcUrl=jdbc:mysql://39.101.221.95:3306/shard_order
spring.shardingsphere.datasource.ds1.username=gavin
spring.shardingsphere.datasource.ds1.password=123456

# 具体的分片规则,基于数据节点
spring.shardingsphere.sharding.tables.order_info.actual-data-nodes=ds$->{0..1}.order_info_$->{1..2}
# 分库的规则
spring.shardingsphere.sharding.tables.order_info.database-strategy.inline.sharding-column=id
spring.shardingsphere.sharding.tables.order_info.database-strategy.inline.algorithm-expression=ds$->{id % 2}
# 分表的规则
spring.shardingsphere.sharding.tables.order_info.table-strategy.inline.sharding-column=user_id
spring.shardingsphere.sharding.tables.order_info.table-strategy.inline.algorithm-expression=order_info_$->{user_id % 2 + 1}

# 具体的分片规则,基于数据节点
spring.shardingsphere.sharding.tables.order_item.actual-data-nodes=ds$->{0..1}.order_item_$->{1..2}
# 分库的规则
spring.shardingsphere.sharding.tables.order_item.database-strategy.inline.sharding-column=order_id
spring.shardingsphere.sharding.tables.order_item.database-strategy.inline.algorithm-expression=ds$->{order_id % 2}
# 分表的规则
spring.shardingsphere.sharding.tables.order_item.table-strategy.inline.sharding-column=user_id
spring.shardingsphere.sharding.tables.order_item.table-strategy.inline.algorithm-expression=order_item_$->{user_id % 2 + 1}

# 绑定表关系
spring.shardingsphere.sharding.binding-tables=order_info,order_item

# 广播表
spring.shardingsphere.sharding.broadcast-tables=province_info
```

> 作业：自己配置使用一个绑定表来进行插入数据和查询数据

```java
// 绑定表插入数据
@Test
void insertOrder(){
  OrderInfo orderInfo = new OrderInfo();
  orderInfo.setId(4).setUserId(10).setOrderStatus(1).setOrderAmount(BigDecimal.valueOf(2499));
  orderInfoService.save(orderInfo);

  OrderItem orderItem = new OrderItem();
  orderItem.setId(2).setOrderId(4).setProductName("易跑跑步机GTS6").setUserId(10);
  orderItemService.save(orderItem);
}
```



## 5. 读写分离配置

首先配置properties的数据源，如果有主机配置就必须要有从机配置

官网配置参考:[https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-spring-boot/](https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-spring-boot/)

```properties
# 指定主从的配置节点
spring.shardingsphere.datasource.names=master0,master0slave0,master1,master1slave0
# master0数据源链接配置
spring.shardingsphere.datasource.master0.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.master0.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.master0.jdbcUrl=jdbc:mysql://39.103.163.215:3306/shard_order
spring.shardingsphere.datasource.master0.username=gavin
spring.shardingsphere.datasource.master0.password=123456
# master0slave0数据源链接配置
spring.shardingsphere.datasource.master0slave0.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.master0slave0.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.master0slave0.jdbcUrl=jdbc:mysql://39.99.212.46:3306/shard_order
spring.shardingsphere.datasource.master0slave0.username=gavin
spring.shardingsphere.datasource.master0slave0.password=123456
# master1数据源链接配置
spring.shardingsphere.datasource.master1.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.master1.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.master1.jdbcUrl=jdbc:mysql://39.101.221.95:3306/shard_order
spring.shardingsphere.datasource.master1.username=gavin
spring.shardingsphere.datasource.master1.password=123456
# master1slave0数据源链接配置
spring.shardingsphere.datasource.master1slave0.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.master1slave0.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.master1slave0.jdbcUrl=jdbc:mysql://localhost:3306/shard_order
spring.shardingsphere.datasource.master1slave0.username=root
spring.shardingsphere.datasource.master1slave0.password=gavin

# 具体的分片规则,基于数据节点
spring.shardingsphere.sharding.tables.order_info.actual-data-nodes=ds$->{0..1}.order_info_$->{1..2}
# 分库的规则
spring.shardingsphere.sharding.tables.order_info.database-strategy.inline.sharding-column=id
spring.shardingsphere.sharding.tables.order_info.database-strategy.inline.algorithm-expression=ds$->{id % 2}
# 分表的规则
spring.shardingsphere.sharding.tables.order_info.table-strategy.inline.sharding-column=user_id
spring.shardingsphere.sharding.tables.order_info.table-strategy.inline.algorithm-expression=order_info_$->{user_id % 2 + 1}

# 具体的分片规则,基于数据节点
spring.shardingsphere.sharding.tables.order_item.actual-data-nodes=ds$->{0..1}.order_item_$->{1..2}
# 分库的规则
spring.shardingsphere.sharding.tables.order_item.database-strategy.inline.sharding-column=order_id
spring.shardingsphere.sharding.tables.order_item.database-strategy.inline.algorithm-expression=ds$->{order_id % 2}
# 分表的规则
spring.shardingsphere.sharding.tables.order_item.table-strategy.inline.sharding-column=user_id
spring.shardingsphere.sharding.tables.order_item.table-strategy.inline.algorithm-expression=order_item_$->{user_id % 2 + 1}

# 绑定表关系
spring.shardingsphere.sharding.binding-tables=order_info,order_item

# 广播表
spring.shardingsphere.sharding.broadcast-tables=province_info

# 读写分离主从关系绑定
spring.shardingsphere.sharding.master-slave-rules.ds0.master-data-source-name=master0
spring.shardingsphere.sharding.master-slave-rules.ds0.slave-data-source-names=master0slave0
# 相当于mycat的schema.xml设置datahost的balance,从库负载均衡的规则,可选值：ROUND_ROBIN，RANDOM，这里是轮询从多个读节点上读取数据，从官网上看到是可以自定义负载均衡的规则的，springcloud的rinbon也支持自定义负载均衡的规则
spring.shardingsphere.sharding.master-slave-rules.ds0.load-balance-algorithm-type=round_robin  

spring.shardingsphere.sharding.master-slave-rules.ds1.master-data-source-name=master1
spring.shardingsphere.sharding.master-slave-rules.ds1.slave-data-source-names=master1slave0
# 相当于mycat的schema.xml设置datahost的balance，从库负载均衡的规则,可选值：ROUND_ROBIN，RANDOM，这里是随机从多个读节点上读取数据
spring.shardingsphere.sharding.master-slave-rules.ds1.load-balance-algorithm-type=random
```

读写分离后，主库从库要自己做主从复制，sharding jdbc是不会帮你把数据写到从库的，mycat也一样的。

源代码：

> 思考题：

在sharding-jdbc里是否有双活的概念？是否像MyCat一样支持热切换，如果不支持，我们如何来解决这个问题？

答：sharding-jdbc没有双活的概念，不支持热切换，它没有mycat 的datahost下面配置多个writehost的概念，sharding-jdbc只是客户端数据源连接的高级管理应用。mysql搭建双主互备模式

## 6. 整合druid连接池注意

<mark>其实sharding-jdbc自己会创建数据连接池的，没必要使用druid连接池</mark>，所以你如果导入了依赖

```xml
<dependency>
	<groupId>com.alibaba</groupId>
	<artifactId>druid-spring-boot-starter</artifactId>
	<version>1.1.23</version>
</dependency>
```

那么会使得sharding-jdbc创建数据源时与druid发送冲突，项目启动失败，如果要依然使用druid来监控数据库，那么需要做两步

第一步，去掉`DruidDataSourceAutoConfigure`自动配置

- 不导入druid-spring-boot-starter包，使用

  ```xml
  <dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>druid</artifactId>
    <version>1.1.20</version>
  </dependency>
  ```

- 或者，启动类排除掉`DruidDataSourceAutoConfigure`自动配置

  ```java
  @SpringBootApplication(exclude={DruidDataSourceAutoConfigure.class})
  ```

第二步，使用JPA做ORM框架，加入如下配置

```java
@Configuration
@EnableConfigurationProperties(JpaProperties.class)
public class DataSourceConfiguration {
	private final JpaProperties jpaProperties;

	private final Environment environment;

	public DataSourceConfiguration(JpaProperties jpaProperties, Environment environment) {
		this.jpaProperties = jpaProperties;
		this.environment = environment;
	}

	@Primary
	@Bean
	public DataSource dataSource() {
		String prefix = "spring.shardingsphere.datasource.";
		String each = this.getDataSourceNames(prefix).get(0);
		try {
			return this.getDataSource(prefix, each);
		} catch (final ReflectiveOperationException ex) {
			throw new ShardingSphereException("Can't find datasource type!", ex);
		}
	}

	@Primary
	@Bean
	public EntityManagerFactory entityManagerFactory() {
		HibernateJpaVendorAdapter vendorAdapter = new HibernateJpaVendorAdapter();
		vendorAdapter.setDatabase(Database.MYSQL);
		vendorAdapter.setGenerateDdl(true);
		vendorAdapter.setShowSql(true);
		LocalContainerEntityManagerFactoryBean factory = new LocalContainerEntityManagerFactoryBean();
		factory.setJpaVendorAdapter(vendorAdapter);
		factory.setPersistenceUnitName("default");
		factory.setPackagesToScan("com.lzm.*");
		factory.setDataSource(this.dataSource());
		factory.setJpaPropertyMap(this.jpaProperties.getProperties());
		factory.afterPropertiesSet();
		return factory.getObject();
	}

	@Bean
	@Primary
	public EntityManager entityManager(EntityManagerFactory entityManagerFactory) {
		return SharedEntityManagerCreator.createSharedEntityManager(entityManagerFactory);
	}

	@Primary
	@Bean
	public PlatformTransactionManager transactionManager(EntityManagerFactory entityManagerFactory) {
		JpaTransactionManager txManager = new JpaTransactionManager();
		txManager.setEntityManagerFactory(entityManagerFactory);
		return txManager;
	}

	private List<String> getDataSourceNames(final String prefix) {
		StandardEnvironment standardEnv = (StandardEnvironment) this.environment;
		standardEnv.setIgnoreUnresolvableNestedPlaceholders(true);
		return null == standardEnv.getProperty(prefix + "name")
				? new InlineExpressionParser(standardEnv.getProperty(prefix + "names")).splitAndEvaluate()
				: Collections.singletonList(standardEnv.getProperty(prefix + "name"));
	}

	@SuppressWarnings("unchecked")
	private DataSource getDataSource(final String prefix, final String dataSourceName) throws ReflectiveOperationException {
		Map dataSourceProps = PropertyUtil.handle(this.environment, prefix + dataSourceName.trim(), Map.class);
		Preconditions.checkState(!dataSourceProps.isEmpty(), "Wrong datasource properties!");
		DataSource result = DataSourceUtil.getDataSource(dataSourceProps.get("type").toString(), dataSourceProps);
		DataSourcePropertiesSetterHolder.getDataSourcePropertiesSetterByType(dataSourceProps.get("type").toString())
				.ifPresent(dataSourcePropertiesSetter -> dataSourcePropertiesSetter.propertiesSet(this.environment, prefix, dataSourceName, result));
		return result;
	}
}
```

但我不喜欢JPA这个ORM框架，所以一般不用。

## 7. 分库分表配置实战

### java配置方式

上面是在application.properties配置分库分表的，也可以使用自定义配置类的方式配置分库分表，参考官网的java配置用户手册：[https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-java/](https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-java/)

rcc的项目，pom.xml导入的依赖

```xml
<dependency>
  <groupId>org.apache.shardingsphere</groupId>
  <artifactId>sharding-jdbc-orchestration</artifactId>
  <version>4.1.1</version>
</dependency>
```

不是xxx-starter，自然就没有xxxAutoConfiguration自动配置类和xxxProperty配置属性类，所以要通过java配置的方式实现sharding分库分表的设置，做法如下：

> 1、application.yaml配置多个数据源

```yaml
spring:
  profiles:
    active: sit
  application:
    name: mcsp-rcc-service-xiejw17
  main:
    allow-bean-definition-overriding: true
  lifecycle:
    timeout-per-shutdown-phase: 40s
  datasource:
    rcc:
      read0:
        url: jdbc:mysql://10.16.92.106:3306/mcsp_rcc_00?Unicode=true&characterEncoding=UTF-8&serverTimezone=UTC&zeroDateTimeBehavior=convertToNull&rewriteBatchedStatements=true&autoReconnect=true
        username: mcsp_rcc_search
        password: eM1eVqq0t
      write0:
        url: jdbc:mysql://10.16.92.106:3306/mcsp_rcc_00?Unicode=true&characterEncoding=UTF-8&serverTimezone=UTC&zeroDateTimeBehavior=convertToNull&rewriteBatchedStatements=true&autoReconnect=true
        username: mcsp_rcc_user
        password: Ppa5zyiS2
      read1:
        url: jdbc:mysql://10.16.92.106:3306/mcsp_rcc_01?Unicode=true&characterEncoding=UTF-8&serverTimezone=UTC&zeroDateTimeBehavior=convertToNull&rewriteBatchedStatements=true&autoReconnect=true
        username: mcsp_rcc_search
        password: eM1eVqq0t
      write1:
        url: jdbc:mysql://10.16.92.106:3306/mcsp_rcc_01?Unicode=true&characterEncoding=UTF-8&serverTimezone=UTC&zeroDateTimeBehavior=convertToNull&rewriteBatchedStatements=true&autoReconnect=true
        username: mcsp_rcc_user
        password: Ppa5zyiS2
```

![](\assets\images\2021\springcloud\sharding-jdbc-1.jpg)

shard-count=8 表示数据库8个分片，也就是分8个库

> 2、EnvironmentConfig.java，将物理数据源注册到spring容器

```java
@Configuration
public class EnvironmentConfig implements BeanDefinitionRegistryPostProcessor, EnvironmentAware {
    public static Environment environment;

    private static final List<String> modules = new ArrayList<>();
    static {
        modules.add("ivc");
        modules.add("rcc");
        modules.add("mcc");
        modules.add("smc");
    }
    @Override
    public void setEnvironment(Environment env) {
        environment = env;
    }

    @Override
    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry beanDefinitionRegistry) throws BeansException {
        registerBeanDefinition( beanDefinitionRegistry);
    }

    @Override
    public void postProcessBeanFactory(ConfigurableListableBeanFactory configurableListableBeanFactory) throws BeansException {

    }

    public  void registerBeanDefinition(  BeanDefinitionRegistry beanDefinitionRegistry){
        for(String module : modules){
            String shardParam = environment.getProperty(CommonConstants.PREFIX + module + ".shard-count");
            int shardCount = Objects.nonNull(shardParam) ? Integer.parseInt(shardParam) : 2;
            String driverClass = environment.getProperty(CommonConstants.PREFIX + module + ".driver-class-name");
            for(int i=0;i<shardCount;i++){
                String read = ".read" + i + ".";
                String write = ".write" + i + ".";
                String readUrl = environment.getProperty(CommonConstants.PREFIX + module + read + "url");
                String readUser = environment.getProperty(CommonConstants.PREFIX + module + read + "username");
                String readPassWord = environment.getProperty(CommonConstants.PREFIX + module + read + "password");
                String writeUrl = environment.getProperty(CommonConstants.PREFIX + module + write + "url");
                String writeUser = environment.getProperty(CommonConstants.PREFIX + module + write + "username");
                String writePassWord = environment.getProperty(CommonConstants.PREFIX + module + write + "password");

                RootBeanDefinition readBeanDefinition = new RootBeanDefinition(DataSource.class);
                configBeanDefinition(readBeanDefinition,module + "-readDataSource" + i, readUser, readPassWord, readUrl,driverClass);

                RootBeanDefinition writeBeanDefinition = new RootBeanDefinition(DataSource.class);
                configBeanDefinition(writeBeanDefinition,module + "-writeDataSource" + i, writeUser, writePassWord, writeUrl,driverClass);

                beanDefinitionRegistry.registerBeanDefinition(module + "-readDataSource" + i, readBeanDefinition);
                beanDefinitionRegistry.registerBeanDefinition(module + "-writeDataSource" + i, writeBeanDefinition);
            }
        }
    }

    private  void configBeanDefinition(RootBeanDefinition beanDefinition, String name, String user, String passWord, String url, String driverClass){
        beanDefinition.setSource("EnvironmentConfig");
        Properties prop = build(url, user, passWord, driverClass);
        beanDefinition.getPropertyValues().add("xaProperties", prop);
        beanDefinition.getPropertyValues().add("minPoolSize",5);
        beanDefinition.getPropertyValues().add("maxPoolSize",50);
        beanDefinition.getPropertyValues().add("maxIdleTime",0);
        beanDefinition.getPropertyValues().add("testQuery","select 1");
        beanDefinition.getPropertyValues().add("xaDataSourceClassName", "com.alibaba.druid.pool.xa.DruidXADataSource");
        beanDefinition.setRole(2);
        beanDefinition.setBeanClass(AtomikosDataSourceBean.class);
    }

    private Properties build(String url,String user,String passWord, String driverClass) {
        Properties prop = new Properties();
        prop.put("url", url);
        prop.put("username", user);
        prop.put("password", passWord);
        prop.put("driverClassName", driverClass);
        return prop;
    }
}
```

EnvironmentConfig实现接口`BeanDefinitionRegistryPostProcessor`和`EnvironmentAware`

- 实现接口`BeanDefinitionRegistryPostProcessor`是为了重写方法`postProcessBeanDefinitionRegistry`将数据源通过bean定义注册器`BeanDefinitionRegistry`注册进spring容器
- 实现接口`EnvironmentAware`环境感知是为了通过环境变量读取application.yml配置文件上面配置的数据库信息

> 3、Shardingsphere的分片配置

业务上ivc\mcc\rcc\smc 4个模块，每个模块都配置8个数据库进行分片，自然每个模块都建一个xxxShardingJdbcConfig配置类：

![](\assets\images\2021\springcloud\sharding-jdbc-2.jpg)

以MccShardingJdbcConfig为例，其他模块配置类一样的

```java
@Configuration
public class MccShardingJdbcConfig implements ApplicationContextAware {
    private static final String MODULE = "mcc";

    private static ApplicationContext applicationContext;

    @Bean(name = "mccShardingDataSource")
    @Primary
    public DataSource getShardingDataSource() throws SQLException {
        // ds逻辑数据源绑定物理数据源做主从设置
        Set<MasterSlaveRuleConfiguration> masterSlaveRuleConfigurationSet = EnvironmentUtil.fillDataSource(MODULE);
        // 数据分片的规则配置类
        ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration();
      // 设置读写分离规则
        shardingRuleConfig.setMasterSlaveRuleConfigs(masterSlaveRuleConfigurationSet);

        // 添加需要进行分库分表的数据表的表分片规则配置对象
        TableRuleConfiguration ivc_invoice_header = getTableRule("mcc_receipt_header",  "ds_${0..7}.mcc_receipt_header_${2021..2026}${['06','07','08','09']}","id");
        shardingRuleConfig.getTableRuleConfigs().add(ivc_invoice_header);

        TableRuleConfiguration mcc_receipt_line = getTableRule("mcc_receipt_line",  "ds_${0..7}.mcc_receipt_line_${2021..2026}${['06','07','08','09']}","id");
        shardingRuleConfig.getTableRuleConfigs().add(mcc_receipt_line);

        TableRuleConfiguration mcc_receipt_relation = getTableRule("mcc_receipt_relation",  "ds_${0..7}.mcc_receipt_relation_${2021..2026}${['06','07','08','09']}","id");
        shardingRuleConfig.getTableRuleConfigs().add(mcc_receipt_relation);

        // 默认的分表策略: 使用不分片的实现类
        shardingRuleConfig.setDefaultTableShardingStrategyConfig(new NoneShardingStrategyConfiguration());
        // 默认的分库策略：使用自定义的策略实现类，对租户编码取模，获取具体的分片数据库
        ShardingStrategyConfiguration dataBaseConfig = new StandardShardingStrategyConfiguration("tenant_code",
                new DataBaseShardingAlgorithm());
        shardingRuleConfig.setDefaultDatabaseShardingStrategyConfig(dataBaseConfig);

        // 返回分片的数据源，使用bean注解放入spring容器
        return ShardingDataSourceFactory.createDataSource(EnvironmentUtil.createDataSourceMap(MODULE, applicationContext), shardingRuleConfig, new Properties());
    }

    /**
     * 获取表分片规则配置对象
     * @param tableName 逻辑数据表名
     * @param tableNodes 分片表节点，由数据源名 + 表名组成，以小数点分隔
     * @param shardingColumn 分片列（键）
     * @return
     */
    private TableRuleConfiguration getTableRule(String tableName, String tableNodes, String shardingColumn) {
        TableRuleConfiguration tableRuleConfig = new TableRuleConfiguration(tableName, tableNodes);
        // 分表策略，使用单分片键的自定义精确分片算法
        tableRuleConfig.setTableShardingStrategyConfig(new StandardShardingStrategyConfiguration(shardingColumn,
                        new SingleKeyModuloTableShardingAlgorithm()));
        return tableRuleConfig;
    }

    @Override
    public void setApplicationContext(ApplicationContext context) throws BeansException {
        applicationContext = context;
    }
```

实现接口`ApplicationContextAware`应用上下文感知接口，是为了获取注入spring容器的物理数据源对象

表分片算法SingleKeyModuloTableShardingAlgorithm.java，实现精确分片算法接口PreciseShardingAlgorithm.java，适用于单分片键的标准分片场景，多分片键可以看看官网的ComplexShardingStrategyConfiguration

```java
public class SingleKeyModuloTableShardingAlgorithm implements PreciseShardingAlgorithm<Long> {
  @Override
  public String doSharding(Collection<String> collection, PreciseShardingValue<Long> shardingValue) {
    String tableName = shardingValue.getLogicTableName(); // 逻辑表名
    // 取分片列值的前6位
    Long key  = Long.valueOf(String.valueOf(shardingValue.getValue()).substring(0, 6));
    return tableName.concat("_").concat(String.valueOf(key)); // 返回具体分片表名
  }
}
```

表分片算法NormalTableShardingAlgorithm.java，实现精确分片算法接口PreciseShardingAlgorithm.java

```java
public class NormalTableShardingAlgorithm implements PreciseShardingAlgorithm<Long> {
    @Override
    public String doSharding(Collection<String> collection, PreciseShardingValue<Long> shardingValue) {
        return shardingValue.getLogicTableName(); // 直接返回逻辑表名
    }
}
```

分库算法DataBaseShardingAlgorithm.java，实现精确分片算法接口PreciseShardingAlgorithm.java

```java
public class DataBaseShardingAlgorithm implements PreciseShardingAlgorithm<String> {
    @Override
    public String doSharding(Collection<String> collection, PreciseShardingValue<String> shardingValue) {
        String value = shardingValue.getValue();
        int shard = value.hashCode()%collection.size();
        Iterator<String> iterator = collection.iterator();
        int temp = 0;
        String ds = null;
        while(iterator.hasNext()){
            ds = iterator.next();
            if(shard == temp){
                break;
            }
            temp ++;
        }
        return ds; // 返回具体的分片数据库
    }
}
```

工具类EvironmentUtil.java

```java
public class EnvironmentUtil {

    /**
     * 获取数据源配置
     * @param module 业务模块名，ivc\mcc\rcc\smc
     * @param applicationContext 应用上下文
     * @return
     */
    public static Map<String, DataSource> createDataSourceMap(String  module, ApplicationContext applicationContext) {
        Map<String, DataSource> result = new HashMap<>();
        String shardParam = EnvironmentConfig.environment.getProperty(CommonConstants.PREFIX + module + ".shard-count");
        int shardCount = Objects.nonNull(shardParam) ? Integer.parseInt(shardParam) : 2;
        for(int i=0;i<shardCount;i++){
            DataSource readDataSource = (DataSource)applicationContext.getBean(module + "-readDataSource" + i);
            DataSource writeDataSource = (DataSource)applicationContext.getBean(module + "-writeDataSource" + i);
            result.put(module + "-writeDataSource" + i, writeDataSource);
            result.put(module + "-readDataSource" + i, readDataSource);
        }
        return result;
    }

    /**
     * 获取数据源的读写分离规则
     * @param module
     * @return
     */
    public static Set<MasterSlaveRuleConfiguration> fillDataSource( String module){
        Set<MasterSlaveRuleConfiguration> masterSlaveRuleConfigurationSet = new HashSet<>();
        String shardParam = EnvironmentConfig.environment.getProperty(CommonConstants.PREFIX + module + ".shard-count");
        int shardCount = Objects.nonNull(shardParam) ? Integer.parseInt(shardParam) : 2;
        for(int i=0;i<shardCount;i++){
            MasterSlaveRuleConfiguration masterSlaveRuleConfig =
                    new MasterSlaveRuleConfiguration("ds_" + i, module + "-writeDataSource" + i, Arrays.asList(module + "-readDataSource" + i));
            masterSlaveRuleConfigurationSet.add(masterSlaveRuleConfig);
        }
        return masterSlaveRuleConfigurationSet;
    }
}
```

> 4、MybatisPlusConfig配置类，绑定sqlsessionFactory与分片数据源

```java
@Configuration
@AutoConfigureAfter(EnvironmentConfig.class)
public class MybatisPlusConfig {
    @Bean
    @ConditionalOnMissingBean({FileNameInterface.class})
    public FileNameInterface defaultFileName() {
        return new DefaultFileNameServiceImpl();
    }

    @Autowired
    PaginationInterceptor paginationInterceptor;

    // 注意冒号:表示当没有配置对应属性时，变量logImpl为null，即默认值null
    @Value("${mybatis-plus.configuration.log-impl:}")
    Class<? extends Log> logImpl;

  // 依赖事务控制器的bean对象先注入spring容器
    @Bean("rccShardingSqlSessionFactory")
    @DependsOn({"transactionManager"})
    @Primary
    public SqlSessionFactory rccShardingSqlSessionFactory(@Qualifier("rccShardingDataSource") DataSource dataSource, @Qualifier("globalConfiguration") GlobalConfig globalConfig) throws Exception {
      // mapper接口的xml文件路径
        String mapperLocations = "classpath:mapping/rcc/shard/*.xml";
      // 数据库表映射的实体类的包路径
        String typeAliasesPackage = "com.midea.mcsp.settlement.rcc.entity.rcc";
        return buildSqlSessionFactory(dataSource, typeAliasesPackage, mapperLocations, globalConfig);
    }

  // smc模块做数据分片的表操作会话工厂sqlsessionFactory绑定smc的分片数据源
    @Bean("smcShardingSqlSessionFactory")
    @DependsOn({"transactionManager"})
    public SqlSessionFactory smcShardingSqlSessionFactory(@Qualifier("smcShardingDataSource") DataSource dataSource, @Qualifier("globalConfiguration") GlobalConfig globalConfig) throws Exception {
        String mapperLocations = "classpath:mapping/smc/shard/*.xml";
        String typeAliasesPackage = "com.midea.mcsp.settlement.rcc.entity.smc";
        return buildSqlSessionFactory(dataSource, typeAliasesPackage, mapperLocations, globalConfig);
    }

   // ivc模块做数据分片的表操作会话工厂sqlsessionFactory绑定ivc的分片数据源
    @Bean("ivcShardingSqlSessionFactory")
    @DependsOn({"transactionManager"})
    public SqlSessionFactory ivcShardingSqlSessionFactory(@Qualifier("ivcShardingDataSource") DataSource dataSource, @Qualifier("globalConfiguration") GlobalConfig globalConfig) throws Exception {
        String mapperLocations = "classpath:mapping/ivc/shard/*.xml";
        String typeAliasesPackage = "com.midea.mcsp.settlement.rcc.entity.ivc";
        return buildSqlSessionFactory(dataSource, typeAliasesPackage, mapperLocations, globalConfig);
    }
  
    @Bean("mccShardingSqlSessionFactory")
    @DependsOn({"transactionManager"})
    public SqlSessionFactory mccShardingSqlSessionFactory(@Qualifier("mccShardingDataSource") DataSource dataSource, @Qualifier("globalConfiguration") GlobalConfig globalConfig) throws Exception {
        String mapperLocations = "classpath:mapping/mcc/shard/*.xml";
        String typeAliasesPackage = "com.midea.mcsp.settlement.rcc.entity.mcc";
        return buildSqlSessionFactory(dataSource, typeAliasesPackage, mapperLocations, globalConfig);
    }

  // 不分片的数据表操作，使用第1个分片数据源做存储
    @Bean("rccSqlSessionFactory")
    @DependsOn({"transactionManager"})
    public SqlSessionFactory rccSqlSessionFactory(@Qualifier("rcc-writeDataSource0") DataSource dataSource, @Qualifier("globalConfiguration") GlobalConfig globalConfig) throws Exception {
        String mapperLocations = "classpath:mapping/rcc/normal/*.xml";
        String typeAliasesPackage = "com.midea.mcsp.settlement.rcc.entity.rcc";
        return buildSqlSessionFactory(dataSource, typeAliasesPackage, mapperLocations, globalConfig);
    }

    // 不分片的数据表操作，使用第1个分片数据源做存储
    @Bean("ivcSqlSessionFactory")
    @DependsOn({"transactionManager"})
    public SqlSessionFactory ivcSqlSessionFactory(@Qualifier("ivc-writeDataSource0") DataSource dataSource, @Qualifier("globalConfiguration") GlobalConfig globalConfig) throws Exception {
        String mapperLocations = "classpath:mapping/ivc/normal/*.xml";
        String typeAliasesPackage = "com.midea.mcsp.settlement.rcc.entity.ivc";
        return buildSqlSessionFactory(dataSource, typeAliasesPackage, mapperLocations, globalConfig);
    }

    // 不分片的数据表操作，使用第1个分片数据源做存储
    @Bean("smcSqlSessionFactory")
    @DependsOn({"transactionManager"})
    public SqlSessionFactory smcSqlSessionFactory(@Qualifier("smc-writeDataSource0") DataSource dataSource, @Qualifier("globalConfiguration") GlobalConfig globalConfig) throws Exception {
        String mapperLocations = "classpath:mapping/smc/normal/*.xml";
        String typeAliasesPackage = "com.midea.mcsp.settlement.rcc.entity.smc";
        return buildSqlSessionFactory(dataSource, typeAliasesPackage, mapperLocations, globalConfig);
    }

    // 不分片的数据表操作，使用第1个分片数据源做存储
    @Bean("mccSqlSessionFactory")
    @DependsOn({"transactionManager"})
    public SqlSessionFactory mccSqlSessionFactory(@Qualifier("mcc-writeDataSource0") DataSource dataSource, @Qualifier("globalConfiguration") GlobalConfig globalConfig) throws Exception {
        String mapperLocations = "classpath:mapping/mcc/normal/*.xml";
        String typeAliasesPackage = "com.midea.mcsp.settlement.rcc.entity.mcc";
        return buildSqlSessionFactory(dataSource, typeAliasesPackage, mapperLocations, globalConfig);
    }

    @Bean
    public GlobalConfig globalConfiguration(MetaObjectHandler myDbFeildFillHandler) {
        GlobalConfig conf = new GlobalConfig();
        conf.setBanner(false);
        GlobalConfig.DbConfig dbConfig = new GlobalConfig.DbConfig();
        dbConfig.setIdType(IdType.ASSIGN_ID);
        dbConfig.setTableUnderline(true);
        dbConfig.setLogicDeleteValue("1");
        dbConfig.setLogicNotDeleteValue("0");
        conf.setDbConfig(dbConfig);
        conf.setMetaObjectHandler(myDbFeildFillHandler);
        return conf;
    }

    @Bean("impalaSqlSessionFactory")
    @DependsOn({"transactionManager"})
    public SqlSessionFactory impalaSqlSessionFactory(@Qualifier("impalaDataSource") DataSource dataSource, @Qualifier("globalConfiguration") GlobalConfig globalConfig) throws Exception {
      // mapper接口的xml文件路径
        String mapperLocations = "classpath:mapping/impala/*.xml";
      // 数据库表映射的实体类的包路径
        String typeAliasesPackage = "com.midea.mcsp.settlement.rcc.entity.impala";
        return buildSqlSessionFactory(dataSource, typeAliasesPackage, mapperLocations, globalConfig);
    }

    private SqlSessionFactory buildSqlSessionFactory(DataSource dataSource, String typeAliasesPackage, String mapperLocations, GlobalConfig globalConfig) throws Exception {
        MybatisSqlSessionFactoryBean sqlSessionFactory = new MybatisSqlSessionFactoryBean();
        sqlSessionFactory.setDataSource(dataSource);
        sqlSessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations));
        sqlSessionFactory.setTypeAliasesPackage(typeAliasesPackage);
        MybatisConfiguration configuration = new MybatisConfiguration();
        configuration.setJdbcTypeForNull(JdbcType.NULL);
        configuration.setMapUnderscoreToCamelCase(true);
        configuration.setCacheEnabled(false);
        //configuration.setLogImpl(org.apache.ibatis.logging.stdout.StdOutImpl.class);
        if (logImpl != null) {
            configuration.setLogImpl(logImpl);
        }
        sqlSessionFactory.setConfiguration(configuration);
        sqlSessionFactory.setPlugins(new Interceptor[]{
                paginationInterceptor
        });
        sqlSessionFactory.setGlobalConfig(globalConfig);
        return sqlSessionFactory.getObject();
    }

    @Bean(name = "userTransaction")
    public UserTransaction userTransaction() throws Throwable {
        UserTransactionImp userTransactionImp = new UserTransactionImp();
        userTransactionImp.setTransactionTimeout(10000);
        return userTransactionImp;
    }

    // 分布式事务管理器
    @Bean(name = "atomikosTransactionManager", initMethod = "init", destroyMethod = "close")
    public TransactionManager atomikosTransactionManager() throws Throwable {
        UserTransactionManager userTransactionManager = new UserTransactionManager();
        userTransactionManager.setForceShutdown(false);
        return userTransactionManager;
    }

    @Bean(name = "transactionManager")
    @DependsOn({"userTransaction", "atomikosTransactionManager"})
    public PlatformTransactionManager transactionManager() throws Throwable {
        return new JtaTransactionManager(userTransaction(), atomikosTransactionManager());
    }
}
```

这里有个impalaDataSource，连接到大数据存储的sql查询引擎impala+kudu，在application.yml配置连接

![](\assets\images\2021\springcloud\sharding-jdbc-3.jpg)

它的数据源配置类，注入到spring容器

```java
@Configuration
public class ImpalaDataSourceConfig {
    @Value("${spring.datasource.impala.url}")
    private String url;

    @Value("${spring.datasource.impala.driver-class}")
    private String driverClass;

    @Value("${spring.datasource.impala.username}")
    private String username;

    @Value("${spring.datasource.impala.password}")
    private String password;

    @Bean("impalaDataSource")
    public DataSource impalaDataSource() {
        // minEvictableIdleTimeMillis 会话连接保持空闲而不被关闭的最小时间，默认30分钟
        // maxEvictableIdleTimeMillis 会话连接保持空闲而不被关闭的最大时间，默认7小时
        DruidDataSource dataSource = new DruidDataSource();
        dataSource.setName("impala-datasource");
        dataSource.setInitialSize(5);
        dataSource.setMinIdle(5);
        dataSource.setMaxActive(150);
        dataSource.setPoolPreparedStatements(true);
        dataSource.setUrl(url);
        dataSource.setDriverClassName(driverClass);
        dataSource.setPassword(password);
        dataSource.setUsername(username);
        dataSource.setValidationQuery("select 1");
        return dataSource;
    }
}
```

> 5、MapperScanerConfig配置类，绑定mapper接口与sqlsessionFactory

```java
@Configuration
@AutoConfigureAfter(MybatisPlusConfig.class)
public class MapperScannerConfig {
  
  // rcc模块做数据分片的表操作的mapper接口绑定rcc的分片sqlSessionFactory
    @Bean
    public MapperScannerConfigurer RccShardingMapperScannerConfigurer() {
        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();
      // 扫描mapper接口的包路径
        mapperScannerConfigurer.setBasePackage("com.midea.mcsp.settlement.rcc.mapper.rcc");
      // 指定对应的sqlsessionFactory
        mapperScannerConfigurer.setSqlSessionFactoryBeanName("rccShardingSqlSessionFactory");
        mapperScannerConfigurer.setAnnotationClass(RccShardingRepository.class);
        return mapperScannerConfigurer;
    }

    @Bean
    public MapperScannerConfigurer IvcShardingMapperScannerConfigurer() {
        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();
        mapperScannerConfigurer.setBasePackage("com.midea.mcsp.settlement.rcc.mapper.ivc");
        mapperScannerConfigurer.setSqlSessionFactoryBeanName("ivcShardingSqlSessionFactory");
       
        mapperScannerConfigurer.setAnnotationClass(IvcShardingRepository.class);
        return mapperScannerConfigurer;
    }

    @Bean
    public MapperScannerConfigurer SmcShardingMapperScannerConfigurer() {
        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();
        mapperScannerConfigurer.setBasePackage("com.midea.mcsp.settlement.rcc.mapper.smc");
        mapperScannerConfigurer.setSqlSessionFactoryBeanName("smcShardingSqlSessionFactory");
        mapperScannerConfigurer.setAnnotationClass(SmcShardingRepository.class);
        return mapperScannerConfigurer;
    }

    @Bean
    public MapperScannerConfigurer MccShardingMapperScannerConfigurer() {
        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();
        mapperScannerConfigurer.setBasePackage("com.midea.mcsp.settlement.rcc.mapper.mcc");
        mapperScannerConfigurer.setSqlSessionFactoryBeanName("mccShardingSqlSessionFactory");
        mapperScannerConfigurer.setAnnotationClass(MccShardingRepository.class);
        return mapperScannerConfigurer;
    }

    @Bean
    public MapperScannerConfigurer MccMapperScannerConfigurer() {
        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();
        mapperScannerConfigurer.setBasePackage("com.midea.mcsp.settlement.rcc.mapper.mcc");
        mapperScannerConfigurer.setSqlSessionFactoryBeanName("mccSqlSessionFactory");
        mapperScannerConfigurer.setAnnotationClass(MccRepository.class);
        return mapperScannerConfigurer;
    }

    @Bean
    public MapperScannerConfigurer IvcMapperScannerConfigurer() {
        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();
        mapperScannerConfigurer.setBasePackage("com.midea.mcsp.settlement.rcc.mapper.ivc");
        mapperScannerConfigurer.setSqlSessionFactoryBeanName("ivcSqlSessionFactory");
        mapperScannerConfigurer.setAnnotationClass(IvcRepository.class);
        return mapperScannerConfigurer;
    }

    @Bean
    public MapperScannerConfigurer RccMapperScannerConfigurer() {
        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();
        mapperScannerConfigurer.setBasePackage("com.midea.mcsp.settlement.rcc.mapper.rcc");
        mapperScannerConfigurer.setSqlSessionFactoryBeanName("rccSqlSessionFactory");
        mapperScannerConfigurer.setAnnotationClass(RccRepository.class);
        return mapperScannerConfigurer;
    }

  // smc模块不分片的数据表操作的mapper接口扫描，绑定smc模块不分片的sqlSessionFactory
    @Bean
    public MapperScannerConfigurer SmcMapperScannerConfigurer() {
        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();
        mapperScannerConfigurer.setBasePackage("com.midea.mcsp.settlement.rcc.mapper.smc");
        mapperScannerConfigurer.setSqlSessionFactoryBeanName("smcSqlSessionFactory");
        mapperScannerConfigurer.setAnnotationClass(SmcRepository.class);
        return mapperScannerConfigurer;
    }

  // impala的kudu大数据表操作的mapper接口扫描
    @Bean
    public MapperScannerConfigurer ImpalaMapperScannerConfigurer() {
        MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();
        mapperScannerConfigurer.setBasePackage("com.midea.mcsp.settlement.rcc.mapper.impala");
        mapperScannerConfigurer.setSqlSessionFactoryBeanName("impalaSqlSessionFactory");
        mapperScannerConfigurer.setAnnotationClass(ImpalaRepository.class);
        return mapperScannerConfigurer;
    }
}
```

最后，这个数据源配置的加载流程如下图：

![](\assets\images\2021\springcloud\sharding-jdbc-4.jpg)

### 整合dynamic动态数据源

pom.xml导入依赖

```xml
<dependency>
  <groupId>com.baomidou</groupId>
  <artifactId>dynamic-datasource-spring-boot-starter</artifactId>
  <version>2.5.6</version>
</dependency>
```

