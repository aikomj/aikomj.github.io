---
layout: post
title: 飞天班第57节：Alibaba-Seata分布式事务框架实战
category: icoding-edu
tags: [mysql]
keywords: springcloud,seata
excerpt: seata AT模式解析，一阶段提交，二阶段提交，安装seata server,创建seata的配置数据库，创建业务数据库，使用nacos，eureka做注册中心，注解@Transactional，@GlobalTransactional测试分布式事务
lock: noneed
---

## 1. 分布式事务Seata-AT模式解析

### 1.1. AT模式分析

AT 模式下，每个数据库被当做是一个  Resource，Seata 里称为 DataSource Resource。业务通过 JDBC 标准接口访问数据库资源时，Seata 框架会对所有请求进行拦截，做一些操作。每个本地事务提交时，Seata RM（Resource Manager，资源管理器） 都会向 TC（Transaction Coordinator，事务协调器） 注册一个分支事务。当请求链路调用完成后，发起方通知 TC 提交或回滚分布式事务，进入二阶段调用流程。此时，TC 会根据之前注册的分支事务回调到对应参与者去执行对应资源的第二阶段。TC 是怎么找到分支事务与资源的对应关系呢？每个资源都有一个全局唯一的资源 ID，并且在初始化时用该 ID 向 TC 注册资源。在运行时，每个分支事务的注册都会带上其资源 ID。这样 TC 就能在二阶段调用时正确找到对应的资源。

<mark>Seata 中有三大模块，分别是 TM、RM 和 TC。 </mark>

- TM 和 RM 是作为 Seata 的客户端与业务系统集成在一起，

- TC 作为 Seata 的服务端独立部署。

![](/assets/images/2020/icoding/mysql/seata.png) 

在 Seata 中，分布式事务的执行流程：

- TM 开启分布式事务（TM 向 TC 注册全局事务记录）；
- 按业务场景，编排数据库、服务等事务内资源（RM 向 TC 汇报资源准备状态 ）；
- TM 结束分布式事务，事务一阶段结束（TM 通知 TC 提交/回滚分布式事务）；
- TC 汇总事务信息，决定分布式事务是提交还是回滚；
- TC 通知所有 RM 提交/回滚 资源，事务二阶段结束。

> 注意：Seata和2PC不同的是Seata的RM是在业务系统端，而2PC的RM则是在数据库服务器端（RM就是数据库），所以2PC在多个RM的情况下对数据库资源链接的占用和锁定是比较耗时的

Seata 会有 4 种分布式事务解决方案，分别是 AT 模式、TCC 模式、Saga 模式和 XA 模式，我们主要学习Seata的AT模式

AT 模式是一种无侵入的分布式事务解决方案。在 AT 模式下，用户只需关注自己的“业务 SQL”，用户的 “业务 SQL” 作为一阶段，Seata 框架会自动生成事务的二阶段提交和回滚操作

![](/assets/images/2020/icoding/mysql/seata-2.png)

### 1.2. AT模式一阶段操作

在一阶段，Seata 会拦截“业务 SQL”，首先解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成“before image”，然后执行“业务 SQL”更新业务数据，在业务数据更新之后，再将其保存成“after image”，最后生成行锁 （不能被第三方再修改）。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。

![](/assets/images/2020/icoding/mysql/seata-3.png)

实现上，Seata对数据源做了封装代理，然后对于数据源的操作处理，就由Seata内部逻辑完成了

### 1.3. AT模式二阶段操作

AT是分为两个阶段的，第一阶段，就是各个阶段本地提交操作；第二阶段会根据第一阶段的情况决定是进行全局提交还是全局回滚操作。

全局提交回滚操作由TM发起，具体为，如果Branch执行没有出现异常，那么就表明各个Branch均执行成功，即进行全局提交，如果某个Branch执行时出现异常，那么就需要进行全局回滚。

> 二阶段提交

二阶段如果是提交的话，因为“业务 SQL”在一阶段已经提交至数据库， 所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。

![](/assets/images/2020/icoding/mysql/seata-4.png)

如果所有Branch RM都执行成功了，那么就进行全局Commit。因为此时我们不用回滚，而每个Branch本地数据库操作已经完成了，那么我们其实主要做的事情就是把本地的Undolog删了即可

> 二阶段回滚

二阶段如果是回滚的话，Seata 就需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用“before image”还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。

![](/assets/images/2020/icoding/mysql/seata-5.png)

> 总结

AT 模式的一阶段、二阶段提交和回滚均由 Seata 框架自动生成，用户只需编写“业务 SQL”，便能轻松接入分布式事务，AT 模式是一种对业务无任何侵入的分布式事务解决方案。



## 2. Seata-Server服务的搭建

### 2.1. 安装Seata Server

GitHub: [https://github.com/seata/seata](https://github.com/seata/seata)

```shell
# 搭建TC(Server)的服务端
wget https://github.com/seata/seata/releases/download/v1.0.0/seata-server-1.0.0.tar.gz
wget https://github.com/seata/seata/releases/download/v1.1.0/seata-server-1.1.0.tar.gz
wget https://github.com/seata/seata/releases/download/v1.2.0/seata-server-1.2.0.tar.gz
# 下载后解压
tar -xvf seata-server-1.0.0.tar.gz 
```

第1步 修改conf/registry.conf

```shell
# 1.修改registry.conf文件
xjwdeMacBook:seata xjw$ cd seata/conf
xjwdeMacBook:conf xjw$ vim registry.conf 
#registry对应注册中心，使用nacos
registry {
  # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa
  type = "nacos" # 使用nacos注册中心

  nacos {
    serverAddr = "139.199.13.139:8848"  # 指定nacos注册中心连接地址
    namespace = ""
    cluster = "default"
  }
  eureka {
    serviceUrl = "http://localhost:8761/eureka"
    application = "default"
    weight = "1"
  }
  redis {
    serverAddr = "localhost:6379"
    db = "0"
  }
  zk {
    cluster = "default"
    serverAddr = "127.0.0.1:2181"
    session.timeout = 6000
    connect.timeout = 2000
  }
  consul {
    cluster = "default"
    serverAddr = "127.0.0.1:8500"
  }
  etcd3 {
    cluster = "default"
    serverAddr = "http://localhost:2379"
  }
  sofa {
    serverAddr = "127.0.0.1:9603"
    application = "default"
    region = "DEFAULT_ZONE"
    datacenter = "DefaultDataCenter"
    cluster = "default"
    group = "SEATA_GROUP"
    addressWaitTime = "3000"
  }
  file {
    name = "file.conf"
  }
}

# config 对应配置中心，使用file.conf配置
config {
  # file、nacos 、apollo、zk、consul、etcd3
  type = "file"

  nacos {
    serverAddr = "localhost"
    namespace = ""
  }
  consul {
    serverAddr = "127.0.0.1:8500"
  }
  apollo {
    app.id = "seata-server"
    apollo.meta = "http://192.168.1.204:8801"
  }
  zk {
    serverAddr = "127.0.0.1:2181"
    session.timeout = 6000
    connect.timeout = 2000
  }
  etcd3 {
    serverAddr = "http://localhost:2379"
  }
  file {
    name = "file.conf"
  }
}
```

第2步修改file.conf,使用file.conf来进行配置，注意这里又个坑，file.conf一定要参考file.conf.example来配置

```shell

# 这个是在注册中心的seata server的服务信息，相当于seata的服务端注册到注册中心
service {
  #transaction service group mapping
  #icodingedu_tx_group：这个稍后要在项目的application.yaml里进行配置
  vgroup_mapping.imall_tx_group = "default"
  #only support when registry.type=file, please don't set multiple addresses
  default.grouplist = "127.0.0.1:8091"
  #degrade, current not support
  enableDegrade = false
  #disable seata
  disableGlobalTransaction = false
}

## transaction log store, only used in seata-server
# 存储到数据库
store {
  ## store mode: file、db
  mode = "db"

  ## file store property
  file {
    ## store location dir
    dir = "sessionStore"
  }

  ## 指定数据库的连接
  db {
    ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc.
    datasource = "dbcp"
    ## mysql/oracle/h2/oceanbase etc.
    db-type = "mysql"
    driver-class-name = "com.mysql.jdbc.Driver"
    url = "jdbc:mysql://127.0.0.1:3306/seata"
    user = "root"
    password = "gavin"
    min-conn = 1
    max-conn = 10
    global.table = "global_table"
    branch.table = "branch_table"
    lock-table = "lock_table"
    query-limit = 100
  }
}
```

### 2.2. 创建Seata的配置数据库

```sql
-- seata的配置数据库在seata server v0.9.0这个版本的发布包里有
-- 先创建一个seata库
-- the table to store GlobalSession data
drop table if exists `global_table`;
create table `global_table` (
  `xid` varchar(128)  not null,
  `transaction_id` bigint,
  `status` tinyint not null,
  `application_id` varchar(32),
  `transaction_service_group` varchar(32),
  `transaction_name` varchar(128),
  `timeout` int,
  `begin_time` bigint,
  `application_data` varchar(2000),
  `gmt_create` datetime,
  `gmt_modified` datetime,
  primary key (`xid`),
  key `idx_gmt_modified_status` (`gmt_modified`, `status`),
  key `idx_transaction_id` (`transaction_id`)
);

-- the table to store BranchSession data
drop table if exists `branch_table`;
create table `branch_table` (
  `branch_id` bigint not null,
  `xid` varchar(128) not null,
  `transaction_id` bigint ,
  `resource_group_id` varchar(32),
  `resource_id` varchar(256) ,
  `lock_key` varchar(128) ,
  `branch_type` varchar(8) ,
  `status` tinyint,
  `client_id` varchar(64),
  `application_data` varchar(2000),
  `gmt_create` datetime,
  `gmt_modified` datetime,
  primary key (`branch_id`),
  key `idx_xid` (`xid`)
);

-- the table to store lock data
drop table if exists `lock_table`;
create table `lock_table` (
  `row_key` varchar(128) not null,
  `xid` varchar(96),
  `transaction_id` long ,
  `branch_id` long,
  `resource_id` varchar(256) ,
  `table_name` varchar(32) ,
  `pk` varchar(36) ,
  `gmt_create` datetime ,
  `gmt_modified` datetime,
  primary key(`row_key`)
);
```

![](/assets/images/2020/icoding/mysql/seata-config-db.jpg)

### 2.3. 创建业务数据库

为两个module创建数据库，业务数据库都必须包含表undo_log，因为如果seata要回滚事务，每个业务数据库的undo_log表都存储着本地事务回滚的日志信息，这就是seata分布式事务回滚的机制原理。

![](/assets/images/2020/icoding/mysql/imall-customer-order.jpg)

- imall_order  订单模块

  ```sql
  create table im_order(
  	id bigint(20) not null comment '主键',
    user_id bigint(20) not null comment '用户id',
    product_id bigint(20) not null comment '产品id',
    count_num int(10) not null comment '购买数量',
    money decimal(10,2) not null comment '花费金额',
    primary key(id)
  )ENGINE=innodb default charset=utf8mb4;
  
  -- 表undo_log在seata server v0.9.0这个版本的发布包里有
  -- 在对应的每个业务数据库还需要创建一个undo_log表
  -- the table to store seata xid data
  -- 0.7.0+ add context
  -- you must to init this sql for you business databese. the seata server not need it.
  -- 此脚本必须初始化在你当前的业务数据库中，用于AT 模式XID记录。与server端无关（注：业务数据库）
  -- 注意此处0.3.0+ 增加唯一索引 ux_undo_log
  drop table if exists `undo_log` ;
  CREATE TABLE `undo_log` (
    `id` bigint(20) NOT NULL AUTO_INCREMENT,
    `branch_id` bigint(20) NOT NULL,
    `xid` varchar(100) NOT NULL,
    `context` varchar(128) NOT NULL,
    `rollback_info` longblob NOT NULL,
    `log_status` int(11) NOT NULL,
    `log_created` datetime NOT NULL,
    `log_modified` datetime NOT NULL,
    `ext` varchar(100) DEFAULT NULL,
    PRIMARY KEY (`id`),
    UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)
  ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
  ```

- imall_customer 用户中心服务模块

  ```sql
  create table im_account(
  	id bigint(20) not null comment '主键',
    user_id bigint(20) not null comment '用户id',
    total decimal(10,2) not null comment '总金额',
    used decimal(10,2) not null comment '已使用',
    residue decimal(10,2) not null comment '余额',
    primary key(id)
  )ENGINE=innodb default charset=utf8mb4;
  
  -- 表undo_log在seata server v0.9.0这个版本的发布包里有
  -- 在对应的每个业务数据库还需要创建一个undo_log表
  -- the table to store seata xid data
  -- 0.7.0+ add context
  -- you must to init this sql for you business databese. the seata server not need it.
  -- 此脚本必须初始化在你当前的业务数据库中，用于AT 模式XID记录。与server端无关（注：业务数据库）
  -- 注意此处0.3.0+ 增加唯一索引 ux_undo_log
  -- rollback_info 回滚信息，类型longlob
  drop table if exists `undo_log`;
  CREATE TABLE `undo_log` (
    `id` bigint(20) NOT NULL AUTO_INCREMENT,
    `branch_id` bigint(20) NOT NULL,
    `xid` varchar(100) NOT NULL,
    `context` varchar(128) NOT NULL,
    `rollback_info` longblob NOT NULL,
    `log_status` int(11) NOT NULL,
    `log_created` datetime NOT NULL,
    `log_modified` datetime NOT NULL,
    `ext` varchar(100) DEFAULT NULL,
    PRIMARY KEY (`id`),
    UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)
  ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
  ```

  

## 3. 创建业务服务模块

**本文使用的版本**

Seata Server 版本v1.1.0

spring-cloud-alibaba-dependencies 版本2.2.1

seata-all 版本1.1.0

> 父项目

1、pom.xml导入依赖

```xml
<dependency>
  <groupId>com.alibaba.cloud</groupId>
  <artifactId>spring-cloud-alibaba-dependencies</artifactId>
  <version>2.1.0.RELEASE</version>
  <type>pom</type>
  <scope>import</scope>
</dependency>
2.2.1.RELEASE 引入的seata-all依赖的版本是1.1.0
```

> moduel项目imall-customer

1、pom.xml导入依赖

```xml
<dependencies>
  <dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
  </dependency>
  <dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
  </dependency>
  <dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
  </dependency>
  <dependency>
    <groupId>org.projectlombok</groupId>
    <artifactId>lombok</artifactId>
  </dependency>
  <dependency>
    <groupId>org.mybatis.spring.boot</groupId>
    <artifactId>mybatis-spring-boot-starter</artifactId>
  </dependency>
  <dependency>
    <groupId>mysql</groupId>
    <artifactId>mysql-connector-java</artifactId>
    <scope>runtime</scope>
  </dependency>
  <dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-seata</artifactId>
    <exclusions>
      <exclusion>
        <groupId>io.seata</groupId>
        <artifactId>seata-all</artifactId>
      </exclusion>
    </exclusions>
  </dependency>
  <dependency>
    <groupId>io.seata</groupId>
    <artifactId>seata-all</artifactId>
    <version>1.0.0</version>
  </dependency>
</dependencies>
```

2、application.properties 配置加上seata的注册

```properties
spring.application.name=imall-customer
server.port=20091
spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848

spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://39.99.210.149:3306/imall_order
spring.datasource.username=gavin
spring.datasource.password=123456

# 注意这里与seata server 的conf/file.conf文件里配置的vgroup_mapping.imall_tx_group = "default" 保持一致
spring.cloud.alibaba.seata.tx-service-group=imall_tx_group

# 使用mybatis
mybatis.mapper-locations=classpath:mapper/*.xml
mybatis.type-aliases-package=com.icoding.supermall.pojo

# 使用mybatis-plus 
mybatis-plus.mapper-locations=classpath:mapper/*.xml
mybatis-plus.type-aliases-package=com.icoding.supermall.pojo
```

3、使用seata的DataSourceProxy做数据源代理，数据源必须自己关联配置到druid里

参考博客：[https://www.cnblogs.com/victorbu/p/12738556.html](https://www.cnblogs.com/victorbu/p/12738556.html)

- 使用Mybatis做ORM框架

  ```java
  package com.icoding.supermall.config;
  
  import com.alibaba.druid.pool.DruidDataSource;
  import io.seata.rm.datasource.DataSourceProxy;
  import org.apache.ibatis.session.SqlSessionFactory;
  import org.mybatis.spring.SqlSessionFactoryBean;
  import org.mybatis.spring.transaction.SpringManagedTransactionFactory;
  import org.springframework.beans.factory.annotation.Value;
  import org.springframework.boot.context.properties.ConfigurationProperties;
  import org.springframework.context.annotation.Bean;
  import org.springframework.context.annotation.Configuration;
  import org.springframework.context.annotation.Primary;
  import org.springframework.core.io.support.PathMatchingResourcePatternResolver;
  
  import javax.sql.DataSource;
  
  @Configuration
  public class DataSourceProxyConfiguration {
  
      @Value("${mybatis.mapper-locations}")
      private String mapperLocations;
  
      @Value("${mybatis.type-aliases-package}")
      private String typeAliasesPackage;
  
      @Bean
      @ConfigurationProperties(prefix = "spring.datasource")
      public DataSource druidDataSource(){
          return new DruidDataSource();
      }
    
      //注意：如果spring-cloud-alibaba-dependencies的版本是2.1.0，则需要配置数据源代理，从2.2.0版本开始，数据源代理自动实现了，不需要再手动配置一个代理类。
      // 2.1.0
      @Bean
      @Primary
      public DataSourceProxy dataSourceProxy(DataSource druidDataSource){
          return new DataSourceProxy(druidDataSource);
      }
  
      @Bean
      public SqlSessionFactory sqlSessionFactory(DataSourceProxy dataSourceProxy) throws Exception{
          SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
          sqlSessionFactoryBean.setDataSource(dataSourceProxy);
          sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations));
          sqlSessionFactoryBean.setTypeAliasesPackage(typeAliasesPackage);
          sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory());
          return sqlSessionFactoryBean.getObject();
      }
    
      // 2.2.0 以上
      @Bean
      public SqlSessionFactory sqlSessionFactory(DataSource druidDataSource) throws Exception{
          SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
          sqlSessionFactoryBean.setDataSource(druidDataSource);
          sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations));
          sqlSessionFactoryBean.setTypeAliasesPackage(typeAliasesPackage);
          sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory());
          return sqlSessionFactoryBean.getObject();
      }
      
  }
  ```
  
- 使用Mybatis-plus做ORM框架，仅配置 DataSource 即可

  ```java
  @Configuration
  public class DataSourceProxyConfiguration {
  
      @Bean
      @ConfigurationProperties(prefix = "spring.datasource")
      public DataSource druidDataSource(){
          return new DruidDataSource();
      }
  }
  ```

4、将registry.conf和file.conf两个配置好的配置文件导入到resources目录下，<mark>注意，这步很重要</mark>

![](/assets/images/2020/icoding/mysql/seata-imall-customer.jpg)

5、web层接口的定义AccountController.java

定义一个修改用户钱包金额的接口，后面imall-order模块下订单通过feign调用该接口，产生分布式事务

```java
@RestController
@RequestMapping("/customer/account")
public class AccountController {
	@Autowired
	AccountService accountService;
  
  @PostMapping("update")
	public R update(@RequestParam(value = "userId") long userId,@RequestParam(value = "used") double used){
		Account account = new Account();
		account.setUserId(userId);
		account.setUsed(new BigDecimal(used));
		accountService.updateAccount(account);
		return  R.ok();
	}
}
```



> moduel项目imall-order

1、配置与imall-customer相同

2、FeignClient接口CustomerClient.java

```java
@FeignClient(name="imall-customer",fallback = CustomerClientHystrixFallback.class)
public interface CustomerClient {
	@PostMapping("/customer/account/update")
	R updateAccount(@RequestParam(value = "userId") long userId, @RequestParam(value = "used") double used);
}
```

3、业务层接口实现类OrderServiceImpl.java

```java
@Slf4j
@Service
public class OrderServiceImpl extends ServiceImpl<OrderMapper, Order> implements OrderService {
	@Autowired
	CustomerClient customerClient;

  @Transactional  // Spring的事务注解，开启一个事务，只能管理本地事务
	@Override
	public void placeOrder(Order order) {
		log.info("insert order......");
		this.save(order);
		
		// int i = 1/0;

		log.info("update account......");
		customerClient.updateAccount(order.getUserId(),order.getMoney().doubleValue());
	}
}
```

4、web层接口的定义OrderController.java

定义一个下订单的接口

```java
@RestController
@RequestMapping("/order")
public class OrderController {
	@Autowired
	OrderService orderService;

	@GetMapping("/placeOrder")
	public R placeOrder(){
		Order order = new Order();
		order.setUserId(10l).setProductId(9l).setCountNum(4).setMoney(new BigDecimal(200));
		orderService.placeOrder(order);
		return R.ok();
	}
}
```

5、启动类

```java
@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)
@EnableDiscoveryClient
@EnableFeignClients
public class OrderApplication {
	public static void main(String[] args) {
		SpringApplication.run(OrderApplication.class,args);
	}
}
```

application.yaml 增加feign调用服务连接超时时间

```yaml
ribbon:
  eureka:
    enabled: true
  eager-load:
    enabled: true
    clients: imall-customer
imall-customer:
  ribbon:
    ConnectTimeout: 3000 #远程调用的连接超时时间
    ReadTimeout: 5000 #远程访问的超时时间    
```



## 4. 测试

1、启动nacos，seata server

```shell
xjwdeMacBook:bin xjw$ pwd
/Users/xjw/Downloads/seata/seata/bin
xjwdeMacBook:bin xjw$ ./seata-server.sh
# 后台启动
nohup seata-server.sh > seata.log 2>&1 &
```

![](/assets/images/2020/icoding/mysql/seata-server-started.jpg)

seata server启动成功，并向nacos注册(这是个bug,它注册服务名就是serverAddr)

![](/assets/images/2020/icoding/mysql/seata-server-register-on-nacos.jpg)

2、启动工程imall-customer、imall-order

![](/assets/images/2020/icoding/mysql/seata-server-register-on-nacos-2.jpg)

3、建一个用户的钱包金额有1000块钱

![](/assets/images/2020/icoding/mysql/seata-imall-acount.jpg)

测试是否正常调用feign

![](/assets/images/2020/icoding/mysql/seata-imall-1.jpg)

业务层接口实现类OrderServiceImpl.java的逻辑是先插入订单，再修改金额

![](/assets/images/2020/icoding/mysql/seata-imall-order-1.jpg)

![](/assets/images/2020/icoding/mysql/seata-imall-acount-2.jpg)

- 测试1: 在中间增加异常

  ```java
  	@Override
  	public void placeOrder(Order order) {
  		log.info("insert order......");
  		this.save(order);
  		
  		int i = 1/0;  // 异常报错
  
  		log.info("update account......");
  		customerClient.updateAccount(order.getUserId(),order.getMoney().doubleValue());
  	}
  ```

  结果：测试发现订单插入成功了，因为没有@Transactional 开启一个事务，所以业务层自动提交了，金额没修改到因为代码还没有走到那一步。

- 测试2: 添加注解@Transactional

  ```java
    @Transactional  // Spring的事务注解，开启一个事务，但只管理本地事务，跨数据库是无法传递事务的
  	@Override
  	public void placeOrder(Order order) {
  		log.info("insert order......");
  		this.save(order);
  		
  		int i = 1/0;  // 异常报错
  
  		log.info("update account......");
  		customerClient.updateAccount(order.getUserId(),order.getMoney().doubleValue());
  	}
  ```

  结果：测试发现订单插入失败回滚，@Transactional控制着本地事务，只要发生错误就会回滚，金额没修改到因为代码还没有走到那一步

- 测试3：插入订单和修改金额调换位置

  ```java
  @Transactional  // Spring的事务注解，开启一个事务，只能管理本地事务
  @Override
  public void placeOrder(Order order) {
    log.info("update account......");
    customerClient.updateAccount(order.getUserId(),order.getMoney().doubleValue());
    
    int i = 1/0;  // 异常报错
  
    log.info("insert order......");
    this.save(order);
  }
  ```

  ![](/assets/images/2020/icoding/mysql/seata-imall-order-2.jpg)

  ![](/assets/images/2020/icoding/mysql/seata-imall-acount-2.jpg)

  ![](/assets/images/2020/icoding/mysql/seata-imall-order-3.jpg)

  结果：与上面结果不同，发生异常后，修改金额还是成功了并没有回滚，因为imall-order和imall-customer连接的数据源不是同一个数据库，@Transactional只能在同一个数据库传递事务 ，也就是说只能管理本地事务。<mark>注解@Transactional 不能解决分布式事务</mark>

  如何解决：按正常逻辑，插入订单和修改金额应该是一个原子性的操作，要么同时成功，要么同时失败。使用Seata框架分布式事务解决方案

- 测试4：使用seata的全局事务注解

  ```java
  // 开启全局事务，rollbackFor可以指定具体的回滚异常类，我这里回滚所有的异常
  @GlobalTransactional(name = "imall.placeOrder",rollbackFor = Exception.class)
  @Override
  public void placeOrder(Order order) {
    log.info("update account......");
    customerClient.updateAccount(order.getUserId(),order.getMoney().doubleValue());
  
    int i = 1/0;
  
    log.info("insert order......");
    this.save(order);
  }
  ```

  验证是否两个数据库都能回滚，重启项目imall-order，再次访问

  ![](/assets/images/2020/icoding/mysql/seata-imall-order-2.jpg)

  ![](/assets/images/2020/icoding/mysql/seata-imall-acount-3.jpg)

![](/assets/images/2020/icoding/mysql/seata-imall-order-3.jpg)

搞定了，发生异常后，金额没有修改，订单没有新增，正常。

查看seata server 的日志，发现回滚的日志记录

![](/assets/images/2020/icoding/mysql/seata-server-do-global-rollback.jpg)

> 总结

service调用的时候添加注解@GlobalTransactional就启用seata，在controller或者service层的方法添加注解@GlobalTransactional开启全局事务

```java
@GlobalTransactional(name="imall.placeOrder",rollbackFor = Exception.class)
public int placeOrder(OrderInfo orderInfo){

  log.info("update account......");
  int accountFlag = accountService.updateAccount(orderInfo.getUser_id(),orderInfo.getMoney());

  int i = 1/0;

  log.info("insert order......");
  int flag = orderMapper.insertOrder(orderInfo);

  return flag*accountFlag;
}
```

**需要重点注意的地方：**要将registry.conf和file.conf两个配置好的配置文件导入到resources目录下



## 5. 使用eureka做注册中心

下面使用Eureka做注册中心

>  新建一个module springboot项目imall-eureka

![](/assets/images/2020/icoding/mysql/imall-eureka-server.jpg)

1、导入依赖

```xml
<dependency>
  <groupId>org.springframework.cloud</groupId>
  <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
</dependency>
```

2、application.yaml配置

```yaml
server:
  port: 8761

spring:
  application:
    name: imall-eureka
  profiles:
    active: dev

eureka:
  instance:
    hostname: localhost
  client:
    registerWithEureka: false
    fetchRegistry: false
    serviceUrl:
      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/
  # server:
    # 自我保护机制, 默认开启
    enable-self-preservation: true
    # 清理失效的时间 5s,默认60秒
    # eviction-interval-timer-in-ms: 5000
```

3、主启动类

```java
@SpringBootApplication
@EnableEurekaServer
public class EurekaServerApplication {
	public static void main(String[] args) {
		SpringApplication.run(EurekaServerApplication.class,args);
	}
}
```

> imall-customer、imall-order的注册中心修改为eureka

1、pom.xml注释nacos discovery的依赖，导入eureka client的依赖

```xml
<dependency>
  <groupId>org.springframework.cloud</groupId>
  <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>
```

2、applicaton.yaml注释nacos discovery的注册中心配置，添加eureka server注册中心的配置

```yaml
eureka:
  client:
    serviceUrl:
      defaultZone: http://localhost:8761/eureka/
  # instance:
    # 每5秒发送心跳，默认30秒
    #lease-renewal-interval-in-seconds: 5
    # 如果30s 之后，服务端没有收到心跳，就代表微服务挂了！默认90秒
    #lease-expiration-duration-in-seconds: 30
```

> seata server 的conf文件修改

registry.conf配置，有两步：1.将type改为 eureka; 2. 修改eureka配置里的application,自定义一个名称imall-seata-tc

```shell
# 将eureka的application进行设置
registry {
  # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa
  type = "eureka"

  nacos {
    serverAddr = "127.0.0.1:8848"
    namespace = ""
    cluster = "default"
  }
  eureka {
    serviceUrl = "http://127.0.0.8761/eureka"
    application = "imall-seata-tc"
    weight = "1"
  }
  redis {
    serverAddr = "localhost:6379"
    db = "0"
  }
  zk {
    cluster = "default"
    serverAddr = "127.0.0.1:2181"
    session.timeout = 6000
    connect.timeout = 2000
  }
  consul {
    cluster = "default"
    serverAddr = "127.0.0.1:8500"
  }
  etcd3 {
    cluster = "default"
    serverAddr = "http://localhost:2379"
  }
  sofa {
    serverAddr = "127.0.0.1:9603"
    application = "default"
    region = "DEFAULT_ZONE"
    datacenter = "DefaultDataCenter"
    cluster = "default"
    group = "SEATA_GROUP"
    addressWaitTime = "3000"
  }
  file {
    name = "file.conf"
  }
}

config {
  # file、nacos 、apollo、zk、consul、etcd3
  type = "file"

  nacos {
    serverAddr = "localhost"
    namespace = ""
  }
  consul {
    serverAddr = "127.0.0.1:8500"
  }
  apollo {
    app.id = "seata-server"
    apollo.meta = "http://192.168.1.204:8801"
  }
  zk {
    serverAddr = "127.0.0.1:2181"
    session.timeout = 6000
    connect.timeout = 2000
  }
  etcd3 {
    serverAddr = "http://localhost:2379"
  }
  file {
    name = "file.conf"
  }
}
```

file.conf，两步：

1. vgroup_mapping的值要与registry文件的eureka.application保持一致

2. default.grouplist 改为imall-seata-tc.grouplist

```shell
# 需要将vgroup_mapping的等号后的内容对应到registry文件的application上
service {
  #transaction service group mapping
  #icodingedu_tx_group：这个稍后要在项目的yaml里进行配置
  vgroup_mapping.imall_tx_group = "imall-seata-tc"
  #only support when registry.type=file, please don't set multiple addresses
  imall-seata-tc.grouplist = "127.0.0.1:8091"
  #degrade, current not support
  enableDegrade = false
  #disable seata
  disableGlobalTransaction = false
}

## transaction log store, only used in seata-server
store {
  ## store mode: file、db
  mode = "db"

  ## file store property
  file {
    ## store location dir
    dir = "sessionStore"
  }

  ## database store property
  db {
    ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc.
    datasource = "dbcp"
    ## mysql/oracle/h2/oceanbase etc.
    db-type = "mysql"
    driver-class-name = "com.mysql.jdbc.Driver"
    url = "jdbc:mysql://127.0.0.1:3306/seata"
    user = "root"
    password = "gavin"
    min-conn = 1
    max-conn = 10
    global.table = "global_table"
    branch.table = "branch_table"
    lock-table = "lock_table"
    query-limit = 100
  }
}
```

修改完后将registry.conf和file.conf重新导入到imall-customer和imall-order的resources目录下

> 测试

依次启动注册中心imall-eureka、seata-server、imall-customer、imall-order

![](/assets/images/2020/icoding/mysql/seata-imall-eureka.jpg)

直接测试我们的分布式事务

```java
@GlobalTransactional(name = "imall.placeOrder",rollbackFor = Exception.class)
@Override
public void placeOrder(Order order) {
  log.info("update account......");
  customerClient.updateAccount(order.getUserId(),order.getMoney().doubleValue());

  int i = 1/0;

  log.info("insert order......");
  this.save(order);
}
```

![](/assets/images/2020/icoding/mysql/seata-imall-eureka-2.jpg)

查看数据库看看金额没有修改，订单没有新增，说明分布式事务生效了

![](/assets/images/2020/icoding/mysql/seata-imall-acount-3.jpg)

![](/assets/images/2020/icoding/mysql/seata-imall-order-3.jpg)

查看seata server的记录了回滚日志

![](/assets/images/2020/icoding/mysql/seata-imall-eureka-rollback.jpg)

## 6. 事务补偿机制TCC

TCC：Try、Confirm、Cancel三种操作

- 针对每个操作，都要有一个与其对应的补偿（撤销）操作
- 在执行过程中，如果其中一个环节失败，那么这个环节以前的操作都要调用其回滚操作来恢复

> A（DB）->B（Redis）->E（DB）->C（文件）->D（DB）

TCC

- 优点：逻辑清晰，流程简单
- 缺点：数据一致性和性能效率比XA还要差，出错的点比较多

TCC属于应用层的一种补偿方式，需要大量的代码开发，通过中间环节(DB,Redis,Monogo)保存数据的中间状态，对于开发人员的业务和技术要求比较高

建议：TCC只做设计，具体的操作使用人工补偿









