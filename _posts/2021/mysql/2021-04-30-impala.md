---
layout: post
title: 开源大数据分析引擎Impala实战1
category: mysql
tags: [mysql]
keywords: mysql
excerpt: 工作中用到大数据分析的场景，学习Impala，记录下来
lock: noneed
---

以下内容参考自贾传青的《开源大数据分析引擎Impala实战》，Impala 1.3.1版本。

**Hadoop是介于数据库和应用之间的一种既能用于存储和处理数据，又能处理应用业务逻辑的一个混合体，我们通常称之为“数据平台”**。Hadoop解决了磁盘IO的扩展问题，但同时由于基于磁盘IO做的运算，导致其对于某些实时性要求更高的任务无能为力。所以Hadoop 2.3开始支持缓存特性，同时诞生了**像Impala一样的基于内存的运算技术，**去解决实时性要求更高的数据分析任务。

Impala 的存储基于<mark>HDFS</mark>，运算基于表的统计信息生成执行计划，具备资源管理功能，是最像传统数据库的大数据技术。

## 1、Impala

### Impala是什么

Hadoop的使用由HDFS和MapReduce两部分构成，HDFS解决了分布式存储问题，MapReduce解决了分布式运算的问题。MapReduce程序需要使用Java等高级语言编写，这成为了大多传统数据库用户的瓶颈，于是Hive应运而生，我们通过HivelQL(类似SQL)语句启动一个任务，由Hive翻译成一个MapReduce任务，然后给到Hadoop执行。

MapReduce适合用于批处理操作，对实时查询无能为力，Impala应运而生，它抛弃了MapReduce，使用了更类似传统的MPP数据库技术，是一个能够进行快速查询的Clouera核心组件。

百度百科，Impala是什么：

<mark>能查询存储在Hadoop的HDFS和HBase中的PB级大数据的SQL查询引擎</mark>，本身不存储数据，是Hive的替代品，Impala不基于MapReduce算法。 它实现了一个基于守护进程的分布式架构，它负责在同一台机器上运行的查询执行的所有方面，最大的特点是快速查询。

### 安装

使用Cloudera Manager进行安装，安装过程分为4个部分：Cloudera Manager 安装准备、Cloudera Manager及CDH安装、Hive安装、Impala安装

> 1、Cloudera Manager 安装准备

Cloudera Manager 简称CM

具体参考书本

> 2、CM及CDH安装

具体参考书本

> 3、Hive安装

具体参考书本

> 4、Impala安装

具体参考书本



## 2、入门示例

### 数据加载

要使用Impala，首先要将数据加载进去，有两种途径

- 使用外部表

  适用于有数据文件的情况，将数据文件拷贝到HDFS上，建立一张Impala外部表，将它的存储位置指向数据文件即可。

- 通过Insert插入数据

  适用于没有数据文件的情况，需要通过对其他表的数据进行过滤转换生成新的数据。

> 1、使用外部表

**第一步准备数据**

数据文件tab1.csv如下：

```sh
1,true,123.123,2012-10-24 08:55
2,false,143.123,2012-10-25 08:55
3,false,155.103,2012-8-24 08:55
....
10000,true,178.123,2012-11-21 08:55
```

数据文件tab2.csv

```java
1,true,1237.123
2,false,123.5
```

查看原始HDFS上impala的默认目录

![](\assets\images\2021\mysql\hdfs.jpg)

为tab1、tab2建立目录

![](\assets\images\2021\mysql\hdfs-2.jpg)

将本地文件系统的数据文件上传到HDFS上

![](\assets\images\2021\mysql\hdfs-3.jpg)

**第二步创建表**

在hadoop-cs1节点上，连接到impala-shell，创建三张表，tab1、tab2、tab3，其中tab1,tab2为外部表，直接使用HDFS上的数据文件。tab3为内部表，通过表tab1、tab2的数据生成

创建表脚本参考书本，后续补上。

```sh
[root@hadoop-cs1 ~]# su - impala
...
[hadoop-cs1:21000]>
# 查看所有表
[hadoop-cs1:21000]> show tables;
# 查看表的定义
[hadoop-cs1:21000]> desc tab1;
```

**第三步加载数据**

对于表tab1,tab2 是外部表，表定义时与数据文件的位置已关联起来，不需要额外的数据加载过程。

![](\assets\images\2021\mysql\impala-shell-1.jpg)

> 2、通过Insert插入数据

此时，表tab3是没有数据的，我们通过Insert 语句将表tab1、tab2的数据经过关联，转换插入到表tab3中，在hadoop-cs1节点上，连接到impala-shell

![](\assets\images\2021\mysql\impala-shell-2.jpg)

`OVERWRITE`关键字表示使用查询结果覆盖表中已经存在的数据

插入之后，我们即可从表tab3查询出数据

![](\assets\images\2021\mysql\impala-shell-3.jpg)

<mark>Impala插入数据后不需要做COMMIT 操作</mark>

Impala表的数据都是存储在HDFS上的，所以进行完插入操作之后，Impala会自动为内部表tab3创建一个数据目录，并将数据文件写入其中。

![](\assets\images\2021\mysql\impala-shell-4.jpg)

### 数据查询

Impala支持大部分传统数据库的聚合Group by，关联，子查询等操作，

### 分区表

Impala的分区表概念与Mysql的分区表一样，也会将某个分区的数据单独存放，当我们指定的where条件是针对某个分区查询时，Impala就只会扫描给分区的数据文件，大大减少了从磁盘读取的数据量，提高了查询效率

创建数据库external_partitions，要先连接到impala-shell

![](\assets\images\2021\mysql\impala-shell-create-database.jpg)

切换到external_partitions

```sh
[hadoop-cs1:21000] > use external_partitions;
```

![](\assets\images\2021\mysql\impala-shell-create-table.jpg)

这里我们创建了一张分区表，`partitioned by(year string,month string,day string,host string)`表示 (year,month,day,host)作为分区列，`row format delimited fields terminated by ','`表示数据文件以逗号分隔。

<mark>注意</mark>分区列并没有出现在表logs的列定义中。

插入数据

![](\assets\images\2021\mysql\impala-shell-create-table-2.jpg)

查看HDFS上的数据文件

![](\assets\images\2021\mysql\impala-shell-create-table-3.jpg)



### 外部分区表

数据不是以表的形式存储，而是以数据文件的方式存储，但是我们希望以分区表的形式组织这些数据文件，那么可以使用外部分区表。



### 更新元数据

向数据文件写入数据，通过Hive进行操作。

## 3、Impala概念及架构

### Impala服务器组件

Impala服务器是一个分布式，大规模并行处理(MPP)数据库引擎，它包括运行在CDH集群主机上的不同后台进程。

> Impala Daemon

这个进程是运行在集群每个节点上的守护进程，是Impala的核心组件，在每个节点上这个进程的名字称为impalad。主要负责读写数据，接受 impala-shell，Hue, JDBC或者ODBC的查询请求，与集群中的其他节点分布式并行工作，并将本节点的查询结果返回给中心协调者节点(central coordinator)。架构图如下：

![](\assets\images\2021\mysql\impalad-1.png)

我们可以向运行在DataNode上的任何impalad进程提交一个查询，提交查询的这个节点将作为这个查询的“协调者节点”(coordinator)为这个查询提供服务。其他节点的运算结果会被传输到协调者节点，协调者节点将最终的运算结果返回。当使用impala-shell命令进行功能性测试的时候,为了方便起见，我们总是会连接到同一个节点上的impalad。但是对于生产环境中的impala集群而言，必须要考虑到各个节点的负载均衡，建议使用JDBC/ODBC接口以轮询(round-robin)的方式提交到不同的impalad进程上。

为了了解其他节点的健康状况和负载，Impalad进程会一直与 statestore保持通信，用以确保哪个节点是健康的并且可以接受任务的。

当impala集群中创建，修改或者删除了对象，或者进行了INSERT/LOAD  DATAT操作，catalogd进程会向所有的节点广播消息，以保证每个impalad节点都能够及时地了解整个集群中对象元数据的最新状态。后台进程间的通信最大限度的降低了对 REFRESH/INVALIDATE METADATA命令的依赖。(但是对于和impala1.2版本之前的节点通信，还是需要显示指定)。

对impala 2.9或者更高版本，可以控制哪一个节点为查询协调器( query coordinators ),也可以控制哪一个节点为查询协调器(query executors), 能够提高大型集群上高并发工作负载的可扩展性。

> Impala Statestore





> Impala Catalog


